{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aldao Amoedo, Héctor\n",
    "\n",
    "Cabaleiro Pintos, Laura\n",
    "\n",
    "Cotardo Valcárcel, Donato José\n",
    "\n",
    "Romero Conde, José"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   _Librerias_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"StatsBase\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"ScikitLearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.svm._classes.SVC'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Plots\n",
    "using Statistics\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using ScikitLearn.CrossValidation: cross_val_score\n",
    "using ScikitLearn.Pipelines: Pipeline, named_steps, FeatureUnion\n",
    "using ScikitLearn.GridSearch: GridSearchCV \n",
    "@sk_import decomposition: (PCA, FastICA)\n",
    "@sk_import discriminant_analysis: LinearDiscriminantAnalysis\n",
    "@sk_import feature_selection: (SelectKBest, f_classif, mutual_info_classif, RFE)\n",
    "@sk_import impute: SimpleImputer\n",
    "@sk_import linear_model: LogisticRegression\n",
    "@sk_import manifold: (LocallyLinearEmbedding, Isomap)\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "@sk_import neural_network: MLPClassifier\n",
    "@sk_import preprocessing: MinMaxScaler\n",
    "@sk_import svm: SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El punto 1, está completado, aunque creo que el 1.3, donde preparamos los datos transformandolos y rellanando los nulos está mal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cargar los datos y descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables: 563\n",
      "Número de instancias: 10299\n",
      "Número de individuos: 30\n",
      "Número de clases de salida: 6\n"
     ]
    }
   ],
   "source": [
    "df = CSV.read(\"Datos_Practica_Evaluacion_1.csv\", DataFrame)\n",
    "\n",
    "num_instancias, num_variables = size(df)\n",
    "num_individuos = length(unique(df[:, 1]))\n",
    "num_clases_salida = length(unique(df[:, end]))\n",
    "\n",
    "println(\"Número de variables: $num_variables\")\n",
    "println(\"Número de instancias: $num_instancias\")\n",
    "println(\"Número de individuos: $num_individuos\")\n",
    "println(\"Número de clases de salida: $num_clases_salida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos dados ya están cargados, y como podemos observar tienen:\n",
    "* 563 Variables\n",
    "* 10299 Instancias\n",
    "* 30 Individuos\n",
    "* 6 Clases de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calcular porcentaje de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje total de nulos en el conjunto: 0.004656507546905259%\n"
     ]
    }
   ],
   "source": [
    "num_nulos_totales = 0\n",
    "\n",
    "for col ∈ names(df)\n",
    "    num_nulos = count(ismissing, df[:, col])\n",
    "    num_nulos_totales += num_nulos\n",
    "    porcentaje_nulos = (num_nulos / num_instancias) * 100\n",
    "end\n",
    "\n",
    "porcentaje_nulos_totales = (num_nulos_totales / (num_instancias * num_variables)) * 100\n",
    "println(\"Porcentaje total de nulos en el conjunto: $porcentaje_nulos_totales%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparar los datos para las técnicas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rellenar valores faltantes tenemos que hacernos una idea de que tipo de datos encontraremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos rellenados.\n"
     ]
    }
   ],
   "source": [
    "for col ∈ names(df)\n",
    "    if eltype(df[!, col]) == Union{Missing, Float64}\n",
    "        df[ismissing.(df[!, col]), col] .= mean(skipmissing(df[!, col]))\n",
    "        df[!, col] = Float64.(df[!, col]) \n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Valores nulos rellenados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set{DataType} with 3 elements:\n",
       "  String31\n",
       "  Int64\n",
       "  Float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Set([eltype(df[!,col]) for col in names(df)])  # ya no hay missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Segmentar el 10% de los datos usando HoldOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuos en el holdout: [4, 12, 29]\n",
      "Tamaño del conjunto de entrenamiento: 9318\n",
      "Tamaño del conjunto de holdout: 981\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(172)\n",
    "\n",
    "holdout_individuos = shuffle(unique(df[:, :subject]))[1:Int(round(0.1 * length(unique(df[:, :subject]))))]  \n",
    "holdout_df = filter(fila -> fila.subject in holdout_individuos, df)\n",
    "train_df = filter(fila -> !(fila.subject in holdout_individuos), df)\n",
    "\n",
    "println(\"Individuos en el holdout: \", holdout_individuos)\n",
    "println(\"Tamaño del conjunto de entrenamiento: $(size(train_df)[1])\")\n",
    "println(\"Tamaño del conjunto de holdout: $(size(holdout_df)[1])\")\n",
    "\n",
    "holdout_subjects = unique(holdout_df[:, :subject])\n",
    "train_subjects = unique(train_df[:, :subject]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separacion X Y\n",
    "X_train = Array(train_df[!,1:end-1])\n",
    "Y_train = Vector(train_df[!,end])\n",
    "X_test = Array(holdout_df[!,1:end-1])\n",
    "Y_test = Vector(holdout_df[!,end]);\n",
    "# escalado\n",
    "X_train = fit_transform!(MinMaxScaler(), X_train);\n",
    "X_test = fit_transform!(MinMaxScaler(), X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_transformed_data (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_transformed_data(name::String, reductor, X, y)\n",
    "\n",
    "    X_reducida = fit_transform!(reducer, X, y)\n",
    "    plot = scatter(X_reduced[:, 1], X_reduced[:, 2], group=y, legend=:topright, title=name,\n",
    "                xlabel=\"Componente 1\", ylabel=\"Componente 2\", markersize=5)\n",
    "    return plot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `bb` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `bb` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[10]:38"
     ]
    }
   ],
   "source": [
    "resultados = DataFrame(filtrado = String[], reduccion = String[], Accuracy = Float64[])\n",
    "plot_distribucion = @layout [a b c; d e]\n",
    "\n",
    "filtrado = Dict(\n",
    "   #\"nada\" => \"passthrough\",\n",
    "   \"anova\" => SelectKBest(score_func=f_classif),\n",
    "   \"mi\" => SelectKBest(score_func=mutual_info_classif),\n",
    "   \"rfe\" => RFE(LogisticRegression(max_iter=500),n_features_to_select=0.5)\n",
    " )\n",
    "\n",
    "reduccion = Dict(\n",
    "   #\"nada\" => \"passthrough\",\n",
    "   \"pca\" => PCA(),\n",
    "   \"lda\" => LinearDiscriminantAnalysis(),\n",
    "   \"ica\" => FastICA(),\n",
    "   \"isomap\" => Isomap(n_neighbors=25),\n",
    "   \"lle\" => LocallyLinearEmbedding(),\n",
    " )\n",
    "\n",
    "clasificacion = Dict(\n",
    "    \"mlp\" => [MLPClassifier(max_iter=700), Dict(:classifier__hidden_layer_sizes => [[50], [100], [100, 50]])],\n",
    "    \"knn\" => [KNeighborsClassifier(), Dict(:classifier__n_neighbors =>[1, 10, 20])],\n",
    "    \"svm\" => [SVC(), Dict(:classifier__C =>[0.1, 1, 10])]\n",
    ")\n",
    "  \n",
    "for (nombreFiltro, filtro) in filtrado\n",
    "    for (nombreReduccion, reduccion) in reduccion\n",
    "        for (nombreClasificador, valor) in clasificacion\n",
    "\n",
    "            clasificador = valor[1]\n",
    "            parametros_local = valor[2]\n",
    "            modelo = Pipeline([\n",
    "                (\"filtro\", filtro),\n",
    "                (\"reduccion\", reduccion),\n",
    "                (\"classifier\", clasificador) \n",
    "            ])\n",
    "\n",
    "            busqueda = GridSearchCV(modelo, parametros_local; refit=true, cv = 2, n_jobs=3)\n",
    "            fit!(busqueda, X_train, Y_train)\n",
    "            mejorModelo = busqueda.best_estimator_\n",
    "            mejoresParametros = busqueda.best_params_\n",
    "            Y_pred = predict(mejorModelo, X_test)\n",
    "            accuracy = sum(Y_pred .== Y_test) / length(Y_test)\n",
    "            push!(resultados, (nombreFiltro, nombreReduccion,accuracy))\n",
    "            println(\"Filtrado: $nombreFiltro,\\nReducción: $nombreReduccion,\\nClasificador: $nombreClasificador,\\nparámetros: $(mejoresParametros),\\nPrecisión: $accuracy\\n\")\n",
    "        \n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hasta aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid = Dict(\n",
    "    #\"filtrado__pca__n_components\" => [ 50, 100], \n",
    "    \"filtrado\"\n",
    "    \"knn__n_neighbors\" => [ 100, 200], \n",
    ")\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"eliminarNulos\", SimpleImputer())\n",
    "        (\"escalado\", MinMaxScaler())\n",
    "        (\"filtrado\", filtrado)\n",
    "        #(\"reduccionDimensionalidad\", )\n",
    "        (\"knn\",KNeighborsClassifier())\n",
    "        ])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=2)\n",
    "\n",
    "fit!(grid_search, X_train, Y_train)\n",
    "\n",
    "println(\"Mejor modelo: \", grid_search.best_estimator_)\n",
    "println(\"Mejores hiperparámetros: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        (\"eliminarNulos\", SimpleImputer())\n",
    "        (\"escalado\", MinMaxScaler())\n",
    "        (\"filtrado\", FeatureUnion([\n",
    "            (\"pca\",PCA()),\n",
    "            (\"anova\",SelectKBest(score_func=f_classif)),\n",
    "            (\"mi\",SelectKBest(score_func=mutual_info_classif)),\n",
    "            (\"rfe\",RFE(LogisticRegression(),n_features_to_select=0.5)),\n",
    "        ]))\n",
    "        (\"knn\",KNeighborsClassifier())\n",
    "        ])\n",
    "\n",
    "param_grid = Dict(\n",
    "    \"filtrado__pca__n_components\" => [ 50, 100], \n",
    "    \"knn__n_neighbors\" => [ 100, 200], \n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=2)\n",
    "\n",
    "fit!(grid_search, X_train, Y_train)\n",
    "\n",
    "println(\"Mejor modelo: \", grid_search.best_estimator_)\n",
    "println(\"Mejores hiperparámetros: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "selection = SelectKBest(k=1)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = transform(fit!(combined_features, X, y), X)\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# Do grid search over k, n_components and C:\n",
    "\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "param_grid = Dict(:features__pca__n_components=>[1, 2, 3],\n",
    "                  :features__univ_select__k=>[1, 2],\n",
    "                  :svm__C=>[0.1, 1, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid; verbose=10, refit=true)\n",
    "\n",
    "fit!(grid_search, X, y)\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Normalizar usando MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los modelos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 RFE con el método de LogisticRegression con una eliminación del 50% de las variables en cada pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Reducción dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5 LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 MLP con al menos las siguientes arquitecturas: [50], [100] [100, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 KNN con valores de vecindario entre 1, 10 y 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 SVM con el parámetro C con valores 0.1, 0.5 y 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los modelos ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
