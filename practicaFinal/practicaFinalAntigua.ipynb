{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aldao Amoedo, Héctor\n",
    "\n",
    "Cabaleiro Pintos, Laura\n",
    "\n",
    "Cotardo Valcárcel, Donato José\n",
    "\n",
    "Romero Conde, José"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   _Librerias_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"StatsBase\")\n",
    "Pkg.add(\"Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El punto 1, está completado, aunque creo que el 1.3, donde preparamos los datos transformandolos y rellanando los nulos está mal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cargar los datos y descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables: 563\n",
      "Número de instancias: 10299\n",
      "Número de individuos: 30\n",
      "Número de clases de salida: 6\n"
     ]
    }
   ],
   "source": [
    "df = CSV.read(\"Datos_Practica_Evaluacion_1.csv\", DataFrame)\n",
    "\n",
    "num_instancias, num_variables = size(df)\n",
    "num_individuos = length(unique(df[:, 1]))\n",
    "num_clases_salida = length(unique(df[:, end]))\n",
    "\n",
    "println(\"Número de variables: $num_variables\")\n",
    "println(\"Número de instancias: $num_instancias\")\n",
    "println(\"Número de individuos: $num_individuos\")\n",
    "println(\"Número de clases de salida: $num_clases_salida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos dados ya están cargados, y como podemos observar tienen:\n",
    "* 563 Variables\n",
    "* 10299 Instancias\n",
    "* 30 Individuos\n",
    "* 6 Clases de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calcular porcentaje de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje total de nulos en el conjunto: 0.004656507546905259%\n"
     ]
    }
   ],
   "source": [
    "#println(\"Porcentaje de nulos por variable:\")\n",
    "num_nulos_totales = 0\n",
    "for col ∈ names(df)\n",
    "    num_nulos = count(ismissing, df[:, col])\n",
    "    num_nulos_totales += num_nulos\n",
    "    porcentaje_nulos = (num_nulos / num_instancias) * 100\n",
    "    #println(\"$col: $porcentaje_nulos% nulos\")\n",
    "end\n",
    "\n",
    "porcentaje_nulos_totales = (num_nulos_totales / (num_instancias * num_variables)) * 100\n",
    "println(\"Porcentaje total de nulos en el conjunto: $porcentaje_nulos_totales%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparar los datos para las técnicas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rellenar valores faltantes tenemos que hacernos una idea de que tipo de datos encontraremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set([eltype(df[!,col]) for col in names(df)]) # o son flotantes, o flotantes con nulos o string. o int\n",
    "sum([eltype(df[!,col])==String31 for col in names(df)]) # la ultima\n",
    "sum([eltype(df[!,col])==Int64 for col in names(df)]); # la primera\n",
    "\n",
    "#Es decir, todas las columnas que tienen valores faltantes son de tipo númerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos rellenados.\n"
     ]
    }
   ],
   "source": [
    "for col ∈ names(df)\n",
    "    if eltype(df[!, col]) == Union{Missing, Float64}\n",
    "        media_columna = mean(skipmissing(df[!, col]))\n",
    "        cuantos_nulos = sum(ismissing.(df[!, col]))\n",
    "        #println(\"Columna $col reemplaza a sus $cuantos_nulos nulos por $media_columna\")\n",
    "        df[ismissing.(df[!, col]), col] .= media_columna\n",
    "        df[!, col] = Float64.(df[!, col]) \n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Valores nulos rellenados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos variables categóricas a numéricas usando One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding aplicado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "clases = String[]#se usará más tarde\n",
    "for col in names(df)\n",
    "    if eltype(df[!, col]) == String31\n",
    "        categorias = unique(df[!, col])\n",
    "        for categoria in categorias\n",
    "            nombre = \"$(col)_$(categoria)\"\n",
    "            push!(clases, nombre)\n",
    "            nueva_columna = Symbol(nombre)\n",
    "            df[!, nueva_columna] = df[!, col] .== categoria\n",
    "        end\n",
    "        select!(df, Not(col)) # eliminamos la columna original\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"One-Hot Encoding aplicado exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Validamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set{DataType} with 3 elements:\n",
       "  Int64\n",
       "  Bool\n",
       "  Float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Set([eltype(df[!,col]) for col in names(df)])  # ya no hay missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=\n",
    "println(\"Validación de datos:\")\n",
    "\n",
    "# Calcular la cantidad total de valores nulos\n",
    "total_nulos = sum(col -> count(ismissing, col), eachcol(df))\n",
    "println(\"Valores nulos restantes: $total_nulos\")\n",
    "\n",
    "# Verificar tipo de datos de cada columna\n",
    "println(\"Tipos de datos por columna:\")\n",
    "for col in names(df)\n",
    "    println(\"$col: $(eltype(df[!, col]))\")\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DatosPreprocesados.csv\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSV.write(\"DatosPreprocesados.csv\",df) # por si mas tarde se quieren importar directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = CSV.read(\"DatosPreprocesados.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Segmentar el 10% de los datos usando HoldOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuos en el holdout: [4, 12, 29]\n",
      "Tamaño del conjunto de entrenamiento: 9318\n",
      "Tamaño del conjunto de holdout: 981\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(172)\n",
    "\n",
    "individuos = unique(df[:, :subject])  # Extraer individuos\n",
    "\n",
    "num_holdout = Int(round(0.1 * length(individuos)))  # 10% de los individuos\n",
    "holdout_individuos = shuffle(individuos)[1:num_holdout]  # Seleccionar individuos aleatorios\n",
    "\n",
    "holdout_df = filter(fila -> fila.subject in holdout_individuos, df)\n",
    "train_df = filter(fila -> !(fila.subject in holdout_individuos), df)\n",
    "\n",
    "println(\"Individuos en el holdout: \", holdout_individuos)\n",
    "println(\"Tamaño del conjunto de entrenamiento: $(size(train_df)[1])\")\n",
    "println(\"Tamaño del conjunto de holdout: $(size(holdout_df)[1])\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La división es correcta: no hay individuos compartidos entre los conjuntos.\n"
     ]
    }
   ],
   "source": [
    "holdout_subjects = unique(holdout_df[:, :subject])\n",
    "train_subjects = unique(train_df[:, :subject])\n",
    "\n",
    "intersection = intersect(holdout_subjects, train_subjects)\n",
    "\n",
    "if isempty(intersection)\n",
    "    println(\"La división es correcta: no hay individuos compartidos entre los conjuntos.\")\n",
    "else\n",
    "    println(\"Error: Hay individuos compartidos entre los conjuntos.\")\n",
    "    println(\"Individuos compartidos: $intersection\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hacer 5 fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "n_folds = 5\n",
    "\n",
    "fold_indices = randperm(length(individuos))  # Permutar aleatoriamente los índices\n",
    "fold_tamano = Int(round(length(individuos) / n_folds))\n",
    "folds = [individuos[fold_indices[(i - 1) * fold_tamano + 1:min(i * fold_tamano, end)]] for i in 1:n_folds]\n",
    "\n",
    "# Crear folds a nivel de instancias\n",
    "fold_data = []\n",
    "for fold in folds\n",
    "    push!(fold_data, filter(fila -> fila.subject in fold, df)[!,2:end]) # quitamos la columna subject que ya no nos importa\n",
    "    #print(filter(fila -> fila.subject in fold, df)[1,1])\n",
    "end\n",
    "\n",
    "# Imprimir resumen de los folds\n",
    "for (i, fold) in enumerate(fold_data)\n",
    "    println(\"Fold $i:\")\n",
    "#    println(\"Número de participantes: $(length(unique(fold[:, :subject])))\")\n",
    "    println(\"Número de instancias: $(size(fold, 1))\")\n",
    " #   println(\"Participantes: $(unique(fold[:, :subject]))\")\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Normalizar usando MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=\n",
    "function MinMaxScaler(columna)\n",
    "    dt = fit(UnitRangeTransform, (columna))\n",
    "    return StatsBase.transform(dt, columna)\n",
    "end\n",
    "\n",
    "for i ∈ 1:length(fold_data)\n",
    "    for col in names(fold_data[i])\n",
    "        if eltype(fold_data[i][:,col]) == Float64\n",
    "            fold_data[i][:,col] = MinMaxScaler(fold_data[i][:,col])\n",
    "        end\n",
    "    end\n",
    "    println(\"Normalizado el fold $i\")\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los modelos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "using Distributions\n",
    "\n",
    "function anova(fold,α) # diapositiva 26\n",
    "    \n",
    "    # División de Datos en Grupos\n",
    "    \n",
    "    grupos = DataFrame[] \n",
    "    for clase in clases\n",
    "        push!(grupos,filter(fila -> fila[clase] == 1,fold))\n",
    "    end\n",
    "    println(typeof(grupos[1]))\n",
    "    \n",
    "    # Cálculo de la Variabilidad\n",
    "    \n",
    "    medias = Array{Float64}(undef, 0, size(grupos[1],2)) \n",
    "    for grupo in grupos\n",
    "        media_grupo = Float64[]\n",
    "        for col in names(grupo)        \n",
    "            push!(media_grupo, mean(grupo[!,col]))\n",
    "        end\n",
    "        medias = vcat(medias, transpose(media_grupo))\n",
    "    end \n",
    "    println(size(medias))\n",
    "    medias_entre_grupos = [mean(medias[:][i]) for i in 1:size(medias,2)]\n",
    "    \n",
    "    # usaremos implicitamente el hecho de que los grupos tienen el mismo numero de elementos\n",
    "    # notación de de https://en.wikipedia.org/wiki/One-way_analysis_of_variance\n",
    "    \n",
    "    Sb = [sum((medias[:,i] .-  medias_entre_grupos[i]).^2) for i in 1:size(medias,2)]\n",
    "\n",
    "    Sw = zeros(size(medias,2))\n",
    "    for (i, grupo) in enumerate(grupos) \n",
    "        for (j, col) in enumerate(names(grupo))\n",
    "            Sw[j] += sum((grupo[!,col] .- medias[i,j]).^2)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Cálculo del Estadístico F\n",
    "    \n",
    "    F = (Sb./(length(clases)-1)) ./ (Sw./(size(fold,1)-length(clases)))\n",
    "    \n",
    "    # Determinación de la Significancia\n",
    "    \n",
    "    distribucionF = FDist(length(clases)-1, size(fold,1)-length(clases))\n",
    "    indices = BitVector(F .< quantile.(distribucionF,α))\n",
    "    indices[end-6:end].=1\n",
    "    return indices\n",
    "end\n",
    "\n",
    "for i in 1:length(fold_data)\n",
    "    indices = anova(fold_data[i],0.95)\n",
    "    print(indices) # vemos con un cero las variables que se dejan fuera\n",
    "    fold_data[i] = fold_data[i][!,indices]\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold_data # vemos que ahora hay menos columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function kargmax(v, n) \n",
    "    indices_menor_a_mayor = partialsortperm(v, 1:length(v))\n",
    "    #print(indices_menor_a_mayor)\n",
    "    return sort(last(indices_menor_a_mayor,n))\n",
    "end\n",
    "x = [3,6,2,7,4,5,1,4]\n",
    "kargmax(x, 4)\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "using InformationMeasures\n",
    "\n",
    "for i ∈ 1:length(fold_data) # para cada fold\n",
    "    explicativas = []\n",
    "    for x ∈ names(fold_data[i]) # por cada variable explicativa\n",
    "        if eltype(fold_data[i][!,x]) == Float64\n",
    "             # por cada variable respuesta\n",
    "            ix = mean([get_mutual_information(fold_data[i][!,x], fold_data[i][!,y]) for y ∈ last(names(fold_data[i]),6)])\n",
    "            push!(explicativas, ix)\n",
    "            #println(\"Fold $i, variable $x, informacion = $ix\")\n",
    "        end\n",
    "    end\n",
    "    #println(explicativas)\n",
    "    indices = kargmax(explicativas,58) # cogemos las 64 variables más explicativas\n",
    "    for respuesta ∈ length(names(fold_data[i]))-6:length(names(fold_data[i]))\n",
    "        if respuesta ∉ indices\n",
    "            push!(indices, respuesta)\n",
    "        end\n",
    "    end\n",
    "    fold_data[i] = fold_data[i][!,indices]\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold_data # vemos que ahora hay 64 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 RFE con el método de LogisticRegression con una eliminación del 50% de las variables en cada pasada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "using GLM\n",
    "\n",
    "for i ∈ 1:length(fold_data) # para cada fold\n",
    "    #fm = @formula(fold_data[i][!,Activity_WALKING] ~  fold_data[i][!,tBodyAcc-mean()-X] )\n",
    "    #logit = glm(fm, train, Binomial(), ProbitLink())\n",
    "    explicativas = []\n",
    "    respuesta = []\n",
    "    for col in names(fold_data[i])\n",
    "        if eltype(fold_data[i][!,col]) == Float64\n",
    "            push!(explicativas,col)\n",
    "        elseif eltype(fold_data[i][!,col]) == Bool\n",
    "            push!(respuesta,col)\n",
    "        end\n",
    "    end\n",
    " \n",
    "    y = Term(Symbol(respuesta[1]))\n",
    "    x =  +((Term(Symbol(i)) for i ∈ explicativas)...) # https://discourse.julialang.org/t/non-call-expression-encountered/90725/2\n",
    "    formula = y ~  x\n",
    "    logistica = glm(formula, fold_data[i], Binomial(), ProbitLink())\n",
    "    print(logistica)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Reducción dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5 LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 MLP con al menos las siguientes arquitecturas: [50], [100] [100, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 KNN con valores de vecindario entre 1, 10 y 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 SVM con el parámetro C con valores 0.1, 0.5 y 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los modelos ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
